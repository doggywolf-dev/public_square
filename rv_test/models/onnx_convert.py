from ultralytics import YOLO

# Загружаем обученную модель YOLO из файла весов
# Файл best.pt должен находиться в текущей директории или нужно указать к нему путь
model = YOLO('best.pt')

# Экспортируем модель в формат ONNX
model.export(
    format='onnx',       # формат экспорта: ONNX
    imgsz=640,           # размер входного изображения (ширина/высота), на котором обучалась модель
    batch=1,             # размер batch при экспорте (фиксированный)
    device='cpu',        # устройство для экспорта: 'cpu' или 'cuda'
    opset=11,            # версия ONNX opset (11 — совместимая и часто используемая)
    simplify=True,       # попытаться упростить вычислительный граф (удалить лишние узлы)
    dynamic=False,       # отключаем динамические размеры (фиксированный размер входа)
    half=False,          # не использовать FP16, экспортируем в FP32
    nms=True             # включить NMS (постобработку) прямо внутри ONNX-модели
)

import onnx

# Загружаем сохранённую ONNX-модель
m = onnx.load("best.onnx")

# Выводим имена выходных тензоров и их размеры
for o in m.graph.output:
    # o.name — имя выхода,
    # o.type.tensor_type.shape.dim — список размерностей тензора
    print(o.name, [d.dim_value for d in o.type.tensor_type.shape.dim])

# Выводим множество всех типов операций, используемых в графе модели
# Это полезно для диагностики и проверки поддержки операций целевым фреймворком (TensorRT, OpenVINO и т.п.)
print({n.op_type for n in m.graph.node})